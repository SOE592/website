---
title: "Package reviews"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 1
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

<br>

For assignment #7 students were asked to provide a summary overview of any package they enjoyed or used frequently. Here is a list of some of their responses, provided with permission.

***

# `{HEEL}`

<br>

Contributed by G Henry

<br>

## Location

https://github.com/gholtgrieve/HEEL

## Vignette(s)

This package does not have any vignettes. 

## Application(s)

There are no websites or applications from this package. 

## Review

This package is a collection of functions that have been written by members of the Holtgrieve Ecosystem Ecology Lab that generally are all related to stable isotope data analysis. Personally, I most frequently use the "EA.NACHO" functionality of the package, which takes raw stable isotope analysis data and finalizes that data by comparing it with a known standard value. It also makes graphs to check the accuracy and precision of the mass spec and elemental analyzer and drift corrects the data. It outputs a PDF file that has lots of helpful information about the samples being analyzed. This package is easy to use and has lots of good documentation to help the user understand how to use it and what it is doing which I like. There is nothing specific that I wish it did differently, but it also took a few versions to get it working how it currently is. When I first started using this package it was still in development and so some of the functionality didn't work well yet. I would only reccommend this package to people also using the SAFS EA and mass spec because a lot of the functionality is specific to our system. 

***

# `{dadjokeapi}`

<br>

Contributed by J Peraza

<br>


## Location

You can access this package from GitHub by installing: 

```{r, eval = FALSE}
# install.packages("devtools")
devtools::install_github("jhollist/dadjokeapi")
```

And it is also on CRAN:

```{r, eval = FALSE}
install.packages("dadjokeapi")
```

## Vignette(s)

This package unfortunately has no vignettes, which is extremely disappointing--I think this needs to change. But, there is a standard help file when you run.

```{r, eval = FALSE}
?groan
```

## Application(s)

There is one application of this package, and it's this incredible website: https://icanhazdadjoke.com/. The package is used in this website to generate a new dad joke every time you click the green button "new joke" at the top of the webpage. 

A basic application of the package:

```{r, echo = TRUE, eval = FALSE}
dadjokeapi::groan()
```

Here is the generated joke:

**Today, my son asked "Can I have a book mark?" and I burst into tears. 11 years old and he still doesn't know my name is Brian.**

## Review

The primary purpose of this package, as defined by the creator themselves, is to "make you laugh in spite of yourself." Whenever you are feeling down, just generate a new dad joke for giggles. What I really like about this package is its simplicity in that it is a single function. A plus is the function being named "groan," it can't get better than that. I do wish this package had more functions. For example, maybe different functions to generate different dad jokes that fall under certain categories like "one-liners," "corny," "cringeworthy," and "pun-tastic." I think there's real potential here. I 100% recommend this package for anyone who needs a dad joke on the fly!

***

# `{gganimate}`

<br>

Contributed by T Code

<br>

## Availability

Available on both CRAN (use `install.packages("gganimate")` and on GitHub via `install_github('thomasp85/gganimate')`.

## Vignettes

`{gganimate}` has a vignette that includes function definitions, examples of code and the graph outcomes. It also explains how to find your animation, and provides options for additional rendering formats. 

## Applications

There are many blogs that describe the usefulness of gganimate including posts from solarchemist, Medium, R-bloggers, and others that highlight the usefulness of the package. I have seen used to show the progression of COVID cases, the relationship between GDP and life expectancy, and NYC housing trends overtime.

## Review

The purpose of this package is to add animation to an otherwise static graphic. This package allows you animate points to easily show how data changes over time. I like how it builds off of ggplot and is easy to implement on graphs that are already coded. I like how much online chatter there is about this package, it makes it easy to get ideas on how to use it effectively. That being said, it seems that folks online struggle with getting animations to work without additional packages installed. I haven't run into these errors but it shows that in some instances, gganimate isn't as easy as it seems. Overall, I would definitely recommend this package to someone! The graphics produced by this package would be perfect to include in a presentation or on a project website.

***

# `{camtrapR}`

<br>

Contributed by Anonymous

<br>


## Location

You can install the release version of `{camtrapR}` from CRAN:

```{r}
install.packages("camtrapR")
```

or the latest GitHub version (containing recent changes and new features) via:

```{r}
remotes::install_github("jniedballa/camtrapR", build_vignettes = TRUE)
```

## Vignette(s)

The package has 5 formal vignettes that help users navigate it.

1. Organising raw camera trap images in camtrapR

2. Species and Individual Identification

3. Data Extraction from Images and videos, creating occupancy & secr input

4. Data exploration and visualisation

5. Multi-species occupancy models

## Application(s)

The camtrapR package has been used in a wide range of conservation and research projects. For example, the Wildlife Conservation Society has used it for monitoring and research projects relating to wildlife as they use it to process and analyze camera trap data. The package has also been used by researchers at the Smithsonian Institution. They studied the distribution and abundance of large mammals in tropical forests. There are other applications of this package, all demonstrating that it can help analyze camera trap data and estimate parameters such as density, abundance, and behavior of wildlife species.

## Review

The `{camtrapR}` package is a very useful tool for analyzing camera trap data. This package contains a set of functions that can be used to process, analyze, and visualize camera trap data. It is designed to handle challenges associated with camera trap data including missing data and repeated detections. I like that this package is a comprehensive set of functions that are important for the type of data I’m working with as it is very messy in nature. It contains functions that will help me do my analysis including estimating animal abundance, occupancy, activity patterns, and it can also help plot and visualize that data. The documentation and vignettes associated with this package are also very thorough and provide detailed explanations of the functions, their parameters, and examples. As a beginner to this type of camera data analysis, I find this package to be very helpful. Because I haven't spent much time working with this package, I still don't know if there any changes I'd like to see associated with this package, but I think it has been relatively easy to learn compared to other packages. Overall, I would recommend this package to anyone working with camera trap data, as it provides a comprehensive set of tools for processing and analyzing data.

***

# `{ggplot2}`

<br>

Contributed by N Chambers & Anonymous

<br>

## Location

You can install this package on both [CRAN](https://cran.r-project.org/web/packages/ggplot2/index.html) and [Github](https://github.com/tidyverse/ggplot2)

## Vignette(s)

`{ggplot2}` has several vignettes in addition to standard help files. It has three topics covered:

1) aesthetic specifications,

2) extending `{ggplot2}`, and

3) using `{ggplot2}` in packages. 

The first topic is probably the most commonly referred to vignette as it covers the primary calls/arguments when using `{ggplot2}` to plot.

## Application(s)

Since this package is part of the Tidyverse it has a dedicated section on the Tidyverse website. This website provides a lot of detail with regard to how the functions contained in the package can be used. It also has a section with 120 extensions to the package with examples of what they do. One reason I feel the need to learn this package is there are more examples on the internet of how to build figures with ggplot than with base R. Thus there are thousands of websites and pages giving examples of how to use this package to produce useful plots.

There is a website like the one we built, which can be found [here](https://ggplot2.tidyverse.org/). This website includes a variety of resources including a cheat sheet which can be pulled from github [here](https://github.com/rstudio/cheatsheets/blob/main/data-visualization.pdf).

## Review

This package is primarily used for plotting data and developing figures for publications. I like that the package is no more difficult to use or learn that base R plotting, and it uses less code overall to produce similar figures. I also appreciate the amazing amount of support this package has on online resources such as stack overflow and various tutorial websites. It does a great job of being able to produce complex and appealing figures while still maintaining its user friendly functionality when producing exploratory plots. Since I have only used it a few times I only have one complaint so far; I am not a big fan of the grey background that is produced in plots by default. This is a minor complaint however as it can be turned into a transparent background easily. I have found the package to be easy to learn and I am committed to learning to use this in favor of base R. At this point I would reccomend this package to others, it seems to be the standard and I have eoncountered no major downsides with several large upsides. 

The primary purpose of the `{ggplot2}` package is for graphics and visualizing data. This package improves on plotting in base R in that you can easily call aesthetic arguments (e.g., black and white) to create clean, easy-to-read figures. One of the most common uses I have with `{ggplot2}` is its faceting capabilities. With one easy line, `facet_wrap()`, I can break up data into groups and visualize each group side-by-side in subplots. Generally, this package was pretty easy to learn in its basic form. However, learning to customize my figures using `{ggplot2}` took more patience and skill. For example, custom colors can be tricky depending on what you want. I have also found that a `{ggplot2}` call for a single plot can very quickly become dozens of lines of code which becomes a bit cumbersome to edit/review, especiall if annotated with comments. In any case, I think there is a lot of utility in this package, and I have and will continue to recommend this package to other R users.

***

# `{vcfR}`

<br>

Contributed by Anonymous

<br>

## Location

This package is located on Github at https://github.com/knausb/vcfR as well as CRAN.

## Vignette(s)

This package has not one but four formal vignettes. These include a vignette on what a VCF (Variant Call Format) file is, one on a general intro to `{vcfR}`, one on the workflow for `{vcfR}`, and one for converting objects in `{vcfR}` to other data or file formats.

## Application(s)

There are two thorough applications of this package that are both linked in the README. One is an entire website devoted to the package, covering everything from background information on R and file types used (they give a nice background as to what a VCF file is and how it’s structured) as well as many tutorials as to analyses `{vcfR}` can be used for. In addition, they link another website they’ve build all about population genetics and genomics in R, giving a really nice work through of how you can use R to perform all sorts of filtering, visualization, and analyses for population genetic/genomic studies. I was really impressed by all this documentation.

## Review

`{vcfR}` is described as a package to “help visualize, manipulate and quality filter VCF data”. Genetic/genomic data is often stored in VCF files and there exist many tools for filtering, manipulating, and analyzing these data. However, a disadvantage of many of these tools, such as VCFtools, is that they are run in Linux, making any sort of code documentation or data visualization difficult. This can make setting thresholds for filtering difficult as well. `{vcfR}` allows us to visualize this data though and keep records of code and previous filtering steps, allowing for better threshold determination and more consistent filtering across different datasets. An aspect I especially appreciate is how easy it is to output these data to other file formats that may be necessary for additional analyses. The authors of this package did a fantastic job providing all sorts of tutorials and documentation on the applications this package has, as well as how R can be utilized in population genetic/genomic studies in general. This makes learning how to use this package and its various utilities very easy to learn.

The only aspect of this package I’m not a huge fan of is that the functions in `{vcfR}` are designed to only work on a single chromosome. When you have data from across the genome, it can be tedious to have to break data down chromosome by chromosome, especially in organisms like salmonids, which can have chromosome numbers in the high twenties. It would be nice if `{vcfR}` could be expanded to work with data across the genome simultaneously. Overall though I would recommend `{vcfR}` to anyone working with genetic/genomic data.

***

#  `{wesanderson}`

<br>

Contributed by N Doran

<br>

## Location(s)

The `{wesanderson}` package has color palettes based on Wes Anderson films. It is on both GitHub and CRAN. 

```{r}
install.packages("wesanderson")
```

## Vignette(s)

The package does have a vignette but it is not very complete. The most helpful way to learn about applications of this package are on the Github repo:  https://github.com/karthik/`{wesanderson}`

## Application(s)

In the description it has the functions needed to see the palette names and see the different palettes. One of the applications it mentions is the Zissou1 palette (inspired by the Life Aquatic with Steve Zissou) is good for creating heat maps. The end of the description also has a list of examples of this palette being used in publications. There are more applications of it on R bloggers: https://www.r-bloggers.com/2022/07/colorful-r-plots-with-wes-anderson-palettes-pirate-ships/

Most palettes have only 4 to 5 colors in them, but you can include an argument in the function wespalette() to create a continuous gradient to pull more colors from, which is demonstrated in examples in the description file. 

```{r}
names(wes_palettes)
```

My favorite palette is probably the Royal1 palette inspired by the _Royal Tenenbaums_. I've used this palette as inspiration for posters and powerpoint presentations because I like the gradient of warm colors with the blue accent color. Taking the red from Ben Stiller's tracksuit is a nice touch.

```{r}
wes_palette("Royal1")
```

## Review

I'm not familiar with many different R packages so I thought this would be a fun one to highlight after the lecture we had on graphic design and color palettes. As a film nerd I always really liked how color is used in Wes Anderson films and these palettes capture the aesthetics of some of my favorite movies, so that's fun. It doesn't look like the newest film French Dispatch has been added, so I would like to see that because one of the skits has a nice color palette of pink, blue, and yellow that aren't as pastel-like as the Moonrise Kingdom palette with similar colors. 

```{r}
wes_palette("Moonrise3")
```

I don't really have anything else to say--they're color palettes. They are easy to use in both base R and `{ggplot}`, many are color-blind friendly. It's just fun to have cultural references in data science. 

***

# `{patchwork}`

<br>

Contributed by K Veggerby

<br>

## Location

The package is on CRAN and can be installed in RStudio using the following R command: 

```{r}
install.packages("patchwork")
```

## Vignette(s)

There is a [short vignette](https://cran.r-project.org/web/packages/patchwork/vignettes/patchwork.html) going through the basics of patchwork syntax. This is helpful if you are new to patchwork and want to see how it works. The idea is to combine plots, figures, maps etc in R as simply as possible. It also contains many options for more complex or detailed plot combinations. For more detailed examples see: https://patchwork.data-imaginist.com/

If you're interested in learning patchwork, I would spend about 5 minutes on the cran page familiarizing yourself with the basics, and then spend the rest of your time on the package website listed above.

## Application(s)

https://patchwork.data-imaginist.com/

This website built by the developers goes through many examples of how to use patchwork mainly using the mtcars dataset in R. 

## Review

The purpose of patchwork is to combine plots, maps, pictures etc. in R into multiplots as simply as possible. The syntax is such that it visually makes sense to the human eye. 

For instance: 

```{r}
plot1 + plot2 
```

produces a figure that has plot1 and plot2 side by side. 

```{r}
plot1 / plot2 
```

produces a figure that has plot1 and plot2 stacked vertically. 

Beyond the simplicity of the commands and syntax, the package has a huge list of options to customize multiplots and make small tweaks to customize pretty much every aspect of a figure. Different commands can be added on by adding a `+` and another line, in the same way that ggplot adds additional items. Patchwork accepts most R objects as inputs. For instance, you could generate a series of plots in ggplot, and then add them all together with patchwork. 

Example:  `ggplot1`, `gis.shape.file`, `ggplot3`, and `png.object` could be made into a 2 x 2 multiplot using simply:

```{r}
Cool_plot <- (ggplot1 + gis.shape.file) / (ggplot3 + png.object)
```

There are a number of other plot combine packages out there like `{grid}` and `{cowplot}`. While these can be helpful, patchwork generally can do everything that other packages can do, but it does them better or more efficiently with less code. In fact, the creator of (I believe) cowplot has stated that people should just use patchwork for 90% of their plot combination needs. 

Given how easy patchwork is to use and understand, the customization, and the large amount of tutorial/documentation, this should be everyone’s go-to plot combination package. Along with other packages such as ggplot and Rcolorbrewer, patchwork forms part of a core group of data visualization packages that everyone should know. 

***

# `{ss3sim}`

<br>

Contributed by Anonymous

<br>

## Location

The package can be downloaded from Cran or from Github.  

1. Cran

```{r} 
install.packages('ss3sim',
                 repos='https://cran.r-project.org/web/packages/ss3sim/index.html',
                 dependencies=TRUE)
```

2.  Github

```{r}
remotes::install_github("ss3sim/ss3sim",
                        ref = "main",
                        build_vignettes = TRUE, dependencies = TRUE )
```

## Vignette(s)

`{ss3sim}` has a number of useful help files.

There are three documents which are useful when working with `{ss3sim}`. The first is the `README.md`, which is comprehensive and offers notes on the installation, file structure and an example simulation of the package. The `README.md` can be found
[here](https://github.com/ss3sim/ss3sim/blob/main/README.md).

There are three vignettes available on the github which cover  

1) [Introduction](https://ss3sim.github.io/ss3sim/articles/introduction.html)  

2) [Making models](https://github.com/ss3sim/ss3sim/blob/main/vignettes/making-models.Rmd) 

3) [Modifying models](https://github.com/ss3sim/ss3sim/blob/main/vignettes/modifying-models.Rmd).

The package is actively under development by NOAA, and as such the
[discussion board](https://github.com/ss3sim/ss3sim/discussions),on GitHub is particularly useful for resolving queries.

There is also an introduction [avilable on CRAN](https://cran.r-project.org/web/packages/ss3sim/vignettes/introduction.html), but it is deprecated and following the instructions will not allow the user to create simulations. This is particularly problematic as when Google is used to [search for introductory material](https://www.google.com/search?q=introduction+to+ss3sim&oq=introduction+to+ss3sim&aqs=chrome..69i57j69i60l2.4403j0j7&sourceid=chrome&ie=UTF-8), the CRAN intro is the first result.

## Application(s)

The primary application of the package is that it allows users to crate simulated fish populations and estimate them using the [Stock Synthesis 3](https://nmfs-stock-synthesis.github.io/doc/SS330_User_Manual.html) modelling framework.The package has been employed for simulation testing documented in peer-review literature. Notable publications include:

Monnahan et al. ([2016](#ref-monnahan_effect_2016))  
Ono et al. ([2015](#ref-ono_importance_2015))  
Rudd et al. ([2021](#ref-rudd_catch_2021))

## Review

`{ss3sim}` is an R package which allows users to simulate fish stock populations and asses them using [Stock Synthesis 3](https://nmfs-stock-synthesis.github.io/doc/SS330_User_Manual.html) modelling framework. The package was initially developed as part of a graduate class project in the school of Aquatic and fisheries Science, University of Washington, with the project being led by Sean Anderson (Anderson et al. ([2014](#ref-anderson_ss3sim_2014))). Each simulation has three components an Operating model (OM) which represent the true population such as natural mortality *M*, recruitment *R* and fishing mortality *F*,the Estimation method (EM) (Stock assessments, survey data etc) which denotes how the population is to be assessed and the control file, which allows the users how and when they would like to alter the EM and OM.

While the file structure of the does appear cumbersome at first, running a pre-specification (or boiler plate) is realities straightforward by following the introduction vignette. The package allows users to alter SS3 assessments in a relatively straightforward fashion,compared to editing the large .text files which SS3 assessments use. The other nice aspect of the package is there are three boiler plates, each mimicking a different fish life-history pattern. The species are Cod *Gadus morhua*, pacific anchovy *Engraulis mordax* and yellowtail flounder *Pleuronectes ferruginea*.

I would recommend the package to anyone interested in fisheries simulation testing or with `{ss3sim}`. As a user who had no SS3 experience, I was able to alter the boiler plates and simulate the effect of having *F* set far higher than is suitable. The effect of this on a fishery over a time period (I chose 100 years) could then be observed.

## References

Anderson, S.C., Monnahan, C.C., Johnson, K.F., Ono, K., Valero, J.L., 2014. ss3sim: An R Package for Fisheries Stock Assessment Simulation with Stock Synthesis. PLoS ONE 9, e92725. <https://doi.org/10.1371/journal.pone.0092725>

Monnahan, C.C., Ono, K., Anderson, S.C., Rudd, M.B., Hicks, A.C., Hurtado-Ferro, F., Johnson, K.F., Kuriyama, P.T., Licandeo, R.R., Stawitz, C.C., Taylor, I.G., Valero, J.L., 2016. The effect of length bin width on growth estimation in integrated age-structured stock assessments. Fisheries Research, Growth: Theory, estimation, and application in fishery stock assessment models 180, 103–112. <https://doi.org/10.1016/j.fishres.2015.11.002>

Ono, K., Licandeo, R., Muradian, M.L., Cunningham, C.J., Anderson, S.C., Hurtado-Ferro, F., Johnson, K.F., McGilliard, C.R., Monnahan, C.C., Szuwalski, C.S., Valero, J.L., Vert-Pre, K.A., Whitten, A.R., Punt, A.E., 2015. The importance of length and age composition data in statistical age-structured models for marine species. ICES Journal of Marine Science 72, 31–43. <https://doi.org/10.1093/icesjms/fsu007>

Rudd, M.B., Cope, J.M., Wetzel, C.R., Hastie, J., 2021. Catch and Length Models in the Stock Synthesis Framework: Expanded Application to Data-Moderate Stocks. Frontiers in Marine Science 8, 663554. <https://doi.org/10.3389/fmars.2021.663554>

***

# `{FD}`

<br>

Contributed by E Bishop

<br>

## Location

You can find this package on [CRAN](https://cran.r-project.org/web/packages/FD/index.html) and also on [Github](https://github.com/cran/FD) as a read-only mirror of the CRAN repository. 

## Vignette(s)

There are no vignettes as part of this package. 

## Application(s)

I haven't found any applications of this package yet outside of scientific publications. It's a relatively new package. 

## Review

The primary purpose of this package is for community ecologists to analyze functional trait data. Functional traits are characteristics of species that describe the ecological niche they occupy within a community. Once a user has created matrices of site x species and species x trait data they can use this package to calculate several diversity indices using the $dbFD$ function. For example, these indices include functional richness, evenness, and divergence, which are all aspects of alpha (within community) diversity. The diversity indices are based on a Principal Coordinate Analysis (PCoA) and users can extract the PCoA coordinates from the $dbFD$ output to visualize the ordination. I like this package because the output of one function gives quite a bit of information about a community dataset. I do, however, wish there was more documentation and more help files to make it more user-friendly. You have to have your input matrices formatted in a very particular way, and there's no examples online of how to do this, so using the package involves a lot of trial and error therefore making it a little tricky to learn how to use. I would recommend this package because I think the output is super interesting, but in recommending the package to a friend I would also share my R code with them so they could have an easier time getting started. 

***

# `{SIBER}`

<br>

Contributed by C Backstrom

<br>

## Location

You can download the Stable Isotope Bayesian Ellipses in R (`{SIBER}`) package, created by Dr. Andrew Jackson and Dr. Andrew Parnell, on the web both via CRAN (https://cran.r-project.org/web/packages/SIBER/index.html) and via Andrew Jackson's Github repository (https://github.com/AndrewLJackson/SIBER).

## Vignette(s)

The CRAN repository for the `{SIBER}` package offers 11 vignettes demonstrating different features of the R code calculations and their interpretation. Topics covered in these vignettes range from vector statistics on stable isotope biplot centroids to plot customization to differences between comparing community and population isotope biplots.

## Application(s)

The `{SIBER}` package can be used to calculate the overlap in isotopic niche space (e.g., biplots of carbon-13 and nitrogen-15 signatures) between two or more groups of organisms (such as species, populations, or communities) to determine the trophic similarity/difference between these groups. `{SIBER}` biplots have appeared in scientific articles in various areas of biology and ecology since the initial creation of the package in 2011.

## Review

The primary purpose of the `{SIBER}` package is to compare the trophic state of different groups of organisms (e.g., different populations or species) by generating biplots of carbon and nitrogen stable isotopic signatures and producing Bayesian ellipses to statistically compare the overlap in signatures between those different groups. As a coral ecophysiologist, I use `{SIBER}` to quantify the overlap in isotopic signatures between corals and their algal symbionts, interpreting higher percent overlap as a higher exchange of resources (i.e., a higher degree of mutualism) between these two members of coral symbiosis (see [Conti-Jerpe et al. (2020)](https://www.science.org/doi/10.1126/sciadv.aaz5443). 

I really appreciate how easy it is to use this package for both plotting and statistical analysis of isotopic data. The vignettes provide extensive comments explaining every code line and its interpretation, and the generated isotopic biplots are easy to manipulate using your own code. The `{SIBER}` model runs relatively quickly (in my experience, being able to process 4000 Bayesian simulations of sample sets of ~50 per each of 2 groups of data in just a few minutes) and the associated Hotelling’s T2 and centroid data for the ellipses are relatively easy to interpret. Having first learned to use `{SIBER}` without much background in R or R Studio, I can attest that the package is easy to learn to use, and that the package creators are available by email to answer any further questions. 

My only warning for using the `{SIBER}` package would be to keep up to date with the newest discussions of the limitations and applications of the model itself. Especially in coral-centric fields, `{SIBER}` applications are still in their infancy, and many isotopic experts (including those reviewing my manuscripts) often have nuanced interpretations of the results that may not be evident from the previous literature. 

***

# `{tidyr}`

<br>

Contributed by Anonymous

<br>

## Location

This package can be accessed by installing Tidyverse as a whole via CRAN: `install.packages("tidyverse")`.

Alternatively, the singular package can be installed with `install.packages("tidyr")`.

The development version of package can also be installed via GitHub with `devtools::install_github("tidyverse/tidyr")`.

## Vignette(s)

There are 5 categories of functions within the package and they are listed on the [Tidyverse website.](https://tidyr.tidyverse.org/index.html). Each category has extended guides to describe the functions within.

* Pivoting
* Rectangling
* Nesting
* Splitting and Combining
* Making Implicit Values Explicit

## Application(s)

The goal of `{tidyr}` is in the title--it is meant to help you tidy your data! [The website](https://tidyr.tidyverse.org/) provides a cheatsheet and further explanation of various situations that it may be applicable in.

## Review

I learned about `{tidyr}` when taking a very simple Introduction to R course in the final year of my undergraduate career. I was briefly reintroduced to the package in FISH 552/553 and I was glad to be reminded about a tool that could aid in the time-consuming process of cleaning one's data. Because 90% of research is data wrangling, I find that this package can be incredibly useful despite having yet to use it personally. Particularly, it would have been applicable for the dense spatial data of my undergraduate research and made the process of managing more complex data more straightforward. As an individual who is still relatively new to R and coding languages, I find it enticing to streamline a workflow.  

The package highlights the two main properties of tidy data: each column is a variable and each row is an observation. This concept is ideal for consistency in your coding workflow because it arranges your data in the same manner. The structure ultimately enables you to push your data through various functions without worrying about compatibility.  

`{tidyr}` is particular useful for:

* Changing the shape of a data set
* Changing the hierarchy of data set
* Handling deeply nested data sets
* Working with missing values (explicit and implicit)

***

# `{purrr}`

<br>

Contributed by Anonymous

<br>

## Location

You can install `{purrr}` from CRAN with

```{r}
install.packages("purrr")
```


## Vignette(s)

The package does have a formal vignette. It covers topics such as what tools it draws inspiration from as well as the goals of `{purrr}`.

## Application(s)

@joshmccrain on Twitter posted an introduction and application of the package showing its basic functions and how to create models and visualizations with `{purrr}` In his demonstration he created a list of `{ggplot}` objects to apply to a map, which gives you the ability to call them separately.

## Review

I don’t have too much experience with `{purrr}`, but from what I’ve used it for and read about it online I find it really interesting. The package is meant to provide a set of functions that can make your coding more efficient for working with functions and vectors in R. For example the map function completes the same tasks as a for loop but with different coding, like the different R apply functions. Though `{purrr}` functions are named more consistently than apply functions and can make code more readable. I like the consistency of this package, lambda functions are needed as much so it makes navigating data manipulation easier and more readable/reproducible for me. While I’m still learning all of the possibilities of the package, I do not find it hard to figure out, there is very good documentation available for it and lots of online resources for different applications of the function.  I don’t necessarily have any complaints for the package, as it applications for what I have used are simple. I would recommend the `{purrr}` package to those who do not like the application of the apply function family in R, as `{purrr}` can be easier to read and use, though if you are already used to the apply functions, `{purrr}` may not be worth learning.

***

# `{tidyverse}`

<br>

Contributed by Anonymous

<br>

## Install from CRAN

```{r}
install.packages("tidyverse")
```

## Vignettes

[The Tidyverse Manifesto](https://cran.r-project.org/web/packages/tidyverse/vignettes/manifesto.html) 

[Welcome to the Tidyverse](https://cran.r-project.org/web/packages/tidyverse/vignettes/paper.html)  

## Application

The primary website for the package can be found [here](https://tidyverse.tidyverse.org/). There are plenty of online examples for the applications of the package (which is essentially a collection of packages). This book is one example of a pretty comprehensive reference:  

[R for Data Science by Hadley Wickham and Garrett Grolemund](https://r4ds.had.co.nz/introduction.html)  

Additionally, there are plenty of "cheat sheets" for  [plotting](https://statsandr.com/blog/files/ggplot2-cheatsheet.pdf) and [data wrangling](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf), and much more that can be found with a google search! 

## Review

The `{tidyverse}` package is actually a collection of a variety of useful, harmonious packages and is meant to simplify the installation and use those packages. According to their website, the `{tidyverse}` is “an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.” The `{tidyverse}` package and associated methodologies essentially streamline data manipulation and visualization in a way that I find more intuitive and useful as an ecologist (who is also definitely not a coding guru).

***

# `{forcats}`

<br>

Contributed by E Jameson

<br>

## Location

This is a popular tidyverse package and is installed when you install the package `{tidyverse}`. The majority of the information comes from the `{forcats}` website found here https://forcats.tidyverse.org/

The following R code will install the package in R

```{r}
# The easiest way to get forcats is to install the whole tidyverse:
install.packages("tidyverse")

# Alternatively, install just forcats:
install.packages("forcats")

# Or the the development version from GitHub:
# install.packages("devtools")
devtools::install_github("tidyverse/forcats")
```

## Vignettes

Yes, there are great vignettes for the `{forcats}` package. The following article provides examples for the following functions within the `{forcats}` package.

```{r}
fct_infreq()
fct_na_value_to_level()
fct_na_level_to_value()
fct_lump()
fct_reorder()
fct_shuffle()
fct_relevel()
```

## Application

The website linked above provides a lot of different resources including a cheat sheet https://raw.githubusercontent.com/rstudio/cheatsheets/main/factors.pdf

The first example uses the starwars dataset to create a table displaying the number of characters that fall into the top 3 species using `fct_lump()`. The second example creates a bar chart displaying the number of characters with different eye colors. They then sort the bars for aesthetics by reordering the factors with `fct_infreq()`.


## Review

This package was created to make working with factor variables easier. I used this package in a previous research project which involved several factor variables such as plant species, level of invasiveness, and site. I most commonly used it to reorder factors or rename the factor levels for figures and models. I like the easy-to-read function names. It is easy to figure out what they do based on their title. Additionally, as part of the tidyverse this package has very good documentation and examples. The combination of easy-to-read function names and the supporting materials make this package very easy to learn. I have not used the package in a while, but I don't remember encountering any challenges that were not quickly remedied with the existing documentation. I that you could use base R to accomplish similar tasks and therefore the package may be redundant. Overall, however, I would definitely recommend using this package to someone else. Especially as the hex sticker is adorable.
