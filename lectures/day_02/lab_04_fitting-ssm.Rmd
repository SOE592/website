---
title: "Fitting univariate state-space models"
subtitle: "SOE 592 â€“ Intro to Time Series Analysis"
date: "<br>4 Jan 2024"
output:
  html_document:
    theme: simplex
    highlight: textmate
    css: ["lecture_inst.css", "fontawesome.css", "solid.css"]
    toc: true
    toc_float: true
    toc_depth: 3
---

```{r setup, include=FALSE, purl=FALSE}
knitr::opts_chunk$set(
  fig.dim = c(7, 5),
  fig.align = "center"
  )
set.seed(592)
```

# Introduction

Many problems in environmental science can be addressed with state-space models and we've already seen a few examples of how some simple population models can be written as state-space models.  This lab will introduce you to fitting univariate state-space models with the {MARSS} package. Notably, {MARSS} follows the same notation for defining state-space models as we would write on a whiteboard. Also, because {MARSS} was designed to fit mutlivariate state-space models, which we will see later, each of the model elements must be a `matrix` class. This also applies to scalar values such that they're not `numeric` or `integer`.

# Gompertz model

We'll begin by simulating a true state of nature and then corrupting it with some observation error to produce the "data". Specifically, we'll use a discrete-time Gompertz model of density-dependent growth. Recall that the size of a population at time $(N_t)$ is given by

$$
N_t = N_{t-1} ~ \exp(u ~ + ~ (b - 1) \log(N_{t-1}))\exp(w _t)
$$

Taking the log of both sides and substituting $x_t$ for $\log(N_t)$

$$
\begin{align}
\log(N_t) & = \log(N_{t-1}) + u + (b - 1) \log(N_{t-1}) + w_t \\
& \Downarrow \\
x_t &= x_{t-1} + u + (b - 1) x_{t-1} + w_t \\
    &= x_{t-1} + u + b x_{t-1} - x_{t-1} + w_t \\
    &= u + b x_{t-1} + w_t
\end{align}
$$

We generally assume the process errors are Gaussian, such that our full state model is our familiar AR(1) process

$$
x_t = u + b x_{t-1} + w_t \\
~ \\
w_t \sim \text{N}(0, q)
$$

<div class="boxy boxy-red boxy-exclamation">
**Note:** As discussed in lecture, it's difficult to estimate both $u$ and $b$, so we'll assume $u$ = 0.
</div>

## Initial state

So far we have largely ignored an important part of our model definition. Because our state model is an autoregressive process, we must define the initial state when $t$ = 0 $(x_0)$. In theory, $x_0$ is assumed to be a random effect with unknown mean and variance, such that

$$
x_0 \sim \text{N}(\pi,\lambda)
$$

In practice, however, estimating both $\pi$ and $\lambda$ is nearly impossible, so the default is to treat $x_0$ as a fixed (but unknown) effect, such that

$$
x_0 \sim \text{N}(\pi,0).
$$


# Simulate some data

<div class="boxy boxy-blue boxy-clipboard-list">
**Task:** Use a `for()` loop to simulate from the AR(1) state model.
</div>

```{r gompertz_sim, echo = TRUE, eval= TRUE}
## number of time steps
TT <- 40

## strength of density-dependence (0 < b < 1)
bb <- 0.5

## time series of process errors with SD = 1
ww <- rnorm(TT, 0, 1)

## initialize state & set x0 = w0
xx <- ww

## loop over time steps
for(t in 2:TT) {
  xx[t] <- bb * xx[t-1] + ww[t]
}
```

<div class="boxy boxy-blue boxy-clipboard-list">
**Task:** Add some observation error to the true state.
</div>

```{r gomp_obs_error, echo = TRUE, eval= TRUE}
## obs errors with SD = 0.5
vv <- rnorm(TT, 0, 0.5)

## obs data
yy <- xx + vv
```


# Fitting models with {MARSS}

The workhorse function in the {MARSS} package that allows us to fit state-state models is `MARSS()`, which has four important arguments:

```{r, echo=TRUE, eval=FALSE}
MARSS(y, model = NULL, inits = NULL, control = NULL, ...)
```

* `y` is an $n \times T$ `matrix` of data (observations)

* `model` a `list` that defines the state-space model in terms of parameters to be estimated

* `inits` [_optional_] a `list` of initial values for parameters to be estimated

* `control` [_optional_] a `list` of options for controlling fitting algorithms, setting tolerance & convergence parameters, etc


## Fitting models with `MARSS()`

`MARSS()` uses an expanded form of state-space model, such that our biased random walk

$$
\begin{align}
x_t &= x_{t-1} + u + w_t \\
y_t &= x_t + v_t
\end{align}
$$
instead becomes

$$
\begin{align}
x_t &= b x_{t-1} + u + w_t \\
y_t &= Z x_t + a + v_t
\end{align}
$$

with $b = 1$, $Z = 1$, and $a = 0$


## Fitting models with `MARSS()`

State model  
$x_t = b x_{t-1} + u + w_t ~~ \text{with} ~~ w_t \sim \text{N}(0,q)$

Observation model  
$y_t = Z x_t + a + v_t ~~ \text{with} ~~ v_t \sim \text{N}(0,r)$

```{r, echo=TRUE}
mod_list <- list(
  ## state model
  B = matrix(1), U = matrix("u"), Q = matrix("q"),
  ## obs model
  Z = matrix(1), A = matrix(0), R = matrix("r")
  )
```

**Note**: `MARSS()` works with the `matrix` class in **R**, so we have to define any scalar as a $1 \times 1$ matrix


## Fitting models with `MARSS()`

`MARSS()` will do this for us


## Fitting models with `MARSS()`

We can ignore the `inits` and `control` arguments for now and fit the model

```{r, echo=TRUE, eval=FALSE}
## load MARSS package
library(MARSS)
## define the data as an N (rows) x T (cols) matrix
dat <- matrix(yy, nrow = 1, ncol = TT)
## fit the model
mod_fit <- MARSS(y = dat, model = mod_list)
```


## Fitting models with `MARSS()` {.smaller}

```{r brw_fit, echo=FALSE, eval=TRUE}
## load MARSS package
library(MARSS)
## define the data as an N (rows) x T (cols) matrix
dat <- matrix(yy, nrow = 1, ncol = TT)
## fit the model
mod_fit <- MARSS(y = dat, model = mod_list)
```


## A note on model fitting

When we have 2+ observations of process, our estimates of model parameters are much more accurate and precise.

$$
\begin{align}
x_t &= x_{t-1} + u + w_t ~~ \text{with} ~ w_t \sim \text{N}(0,q) \\
~ \\
\begin{bmatrix}
y_1 \\
y_2 \\
\vdots \\
y_n
\end{bmatrix}_t
&=
\begin{bmatrix}
1 \\
1 \\
\vdots \\
1
\end{bmatrix}
x_t + 
\begin{bmatrix}
v_1 \\
v_2 \\
\vdots \\
v_n
\end{bmatrix}_t
~~ \text{with} ~
\mathbf{v_t} \sim \text{MVN}(\mathbf{0},\mathbf{R})
\end{align}
$$



## Extracting fitted model objects

Fitted values are stored in an $N \times T$ matrix (here $N = 1$) accessed with `$states`

Standard errors of fitted values are stored in an $N \times T$ matrix (vector) accessed with `$states.se`

```{r, echo = TRUE, eval = TRUE}
## T x 1 (transposed) vector of states
mod_fits <- t(mod_fit$states)

## T x 1 (transposed) vector of SE's
mod_fits_SE <- t(mod_fit$states.se)
```


## Approximate confidence intervals

We can estimate a $[(1 - \alpha)  \times 100]\%$ confidence interval as

$$
\hat{x} ~ \pm ~ t_{1 - \alpha/2} \times \text{SE}(\hat{x})
$$


## Approximate confidence intervals

```{r brw_CI, eval = TRUE, echo = TRUE}
## upper 95% CI
mod_fits_CI_hi <- mod_fits + qt(p = 0.975, df = TT - 1) * mod_fits_SE

## lower 95% CI
mod_fits_CI_lo <- mod_fits - qt(p = 0.975, df = TT - 1) * mod_fits_SE
```


<!-- ## Plot the model fit & uncertainty -->

<!-- Plot the state and observation -->

<!-- ```{r rw_plot_fit_code, echo=TRUE, eval=FALSE} -->
<!-- plot.ts(xx, lwd = 2, type = "o", pch = 16, col = "#488fdf", -->
<!--         las = 1, ylim = c(min(xx,yy), max(xx,yy)), -->
<!--         ylab = expression(italic(x[t])~~or~~italic(y[t]))) -->
<!-- lines(yy, lwd = 2, type = "o", pch = 16, cex = 1.5, col = "#844870") -->
<!-- lines(mod_fits, lwd = 2, type = "l", cex = 1.5, col = "black") -->
<!-- lines(mod_fits_CI_hi, lwd = 2, type = "l", cex = 1.5, col = "gray") -->
<!-- lines(mod_fits_CI_lo, lwd = 2, type = "l", cex = 1.5, col = "gray") -->
<!-- ``` -->


## Model fit and true states 

```{r rw_plot_fits_states, align.fig="center"}
par(mai = c(0.8,0.8,0,0), omi = c(0,0,0,0))
plot.ts(xx, lwd = 2, type = "o", pch = 16, col = "#488fdf",
        las = 1, ylim = c(min(xx,yy), max(xx,yy)),
        ylab = expression(italic(x[t])~~or~~italic(y[t])))
# lines(yy, lwd = 2, type = "o", pch = 16, cex = 1.5, col = "#844870")
lines(mod_fits, lwd = 2, type = "l", cex = 1.5, col = "black")
lines(mod_fits_CI_hi, lwd = 2, type = "l", cex = 1.5, col = "gray")
lines(mod_fits_CI_lo, lwd = 2, type = "l", cex = 1.5, col = "gray")
```


## Model fit with observations only

```{r rw_plot_fit_nostate, align.fig="center"}
par(mai = c(0.8,0.8,0,0), omi = c(0,0,0,0))
plot.ts(yy, lwd = 2, type = "o", pch = 16, cex = 1.5, col = "#844870",
        las = 1, ylim = c(min(xx,yy), max(xx,yy)),
        ylab = expression(italic(x[t])~~or~~italic(y[t])))
lines(mod_fits, lwd = 2, type = "l", cex = 1.5, col = "black")
lines(mod_fits_CI_hi, lwd = 2, type = "l", cex = 1.5, col = "gray")
lines(mod_fits_CI_lo, lwd = 2, type = "l", cex = 1.5, col = "gray")
```


## Model fit with observations & states 

```{r rw_plot_fit, align.fig="center"}
par(mai = c(0.8,0.8,0,0), omi = c(0,0,0,0))
plot.ts(xx, lwd = 2, type = "o", pch = 16, col = "#488fdf",
        las = 1, ylim = c(min(xx,yy), max(xx,yy)),
        ylab = expression(italic(x[t])~~or~~italic(y[t])))
lines(yy, lwd = 2, type = "o", pch = 16, cex = 1.5, col = "#844870")
lines(mod_fits, lwd = 2, type = "l", cex = 1.5, col = "black")
lines(mod_fits_CI_hi, lwd = 2, type = "l", cex = 1.5, col = "gray")
lines(mod_fits_CI_lo, lwd = 2, type = "l", cex = 1.5, col = "gray")
```


## Evidence for bias

Q: Is there data support for the bias term?

To answer this, we can fit a model without the bias term and compare AICc


## Evidence for bias

We need to modify the model definition for `MARSS()` by setting `U = matrix(0)` 

```{r rw_model, echo=TRUE}
mod_list <- list(
  ## state model
  B = matrix(1), U = matrix(0), Q = matrix("q"),
  ## obs model
  Z = matrix(1), A = matrix(0), R = matrix("r")
  )
```


## Re-fit the model with `MARSS()`

```{r rw_fit, echo = TRUE, eval=TRUE}
## fit the model
mod_fit_2 <- MARSS(y = dat, model = mod_list)
```


## Compare AIC values

```{r compare_AICc, echo = TRUE, eval = TRUE}
## biased RW
mod_fit$AICc

## unbiased RW
mod_fit_2$AICc
```


